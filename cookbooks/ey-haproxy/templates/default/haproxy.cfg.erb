######
#
# For the V7 web stack, haproxy is our load balancer, answering on both ports
# 80 and 443 for client browswer connections. It is responsible for proxying
# the the next correct step in the chain, and is also responsble for eventually
# load balancing requests to the application workers.
#
# Port layout and usage:
#
# 1) HAproxy: 80 / 443
# 2) HAproxy -> nginx HTTP: 8091
# 3) HAproxy -> nginx HTTPs: 8092
# 4) xLB -> nginx HTTP: 8081
# 5) xLB -> nginx HTTPs: 8082
# 6) apps: 8000+200*app_index + worker_index
######


global

  # maximum number of simultaneous active connections from an upstream web server
  ulimit-n 655350
  maxconn 65535

  # Logging to syslog facility local0
  # log   127.0.0.1       local0

  # Distribute the health checks with a bit of randomness
  spread-checks 5

  # Enable socket
  stats socket /var/run/haproxy.sock mode 600 level admin
  stats timeout 2m

  # Uncomment the statement below to turn on verbose logging
  #debug

  # SSL specific setup. This configuration disallows the most vulnerable
  # ciphers, but that limits SSL compatibility on old browsers, such as IE6
  tune.ssl.default-dh-param 2048
  ssl-default-bind-options no-sslv3
  ssl-default-bind-ciphers ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS

# Settings in the defaults section apply to all services (unless you change it,
# this configuration defines one service, called rails).
defaults

  # apply log settings from the global section above to services
  log global

  # Proxy incoming traffic as HTTP requests
  mode http

  # Use the leastconn algorithm (SD-3698)
  balance leastconn

  # Maximum number of simultaneous active connections from an upstream web server
  # per service
  maxconn 65535

  # Log details about HTTP (will change to tcplog automatically if TCP mode is detected)
  option httplog

  # Abort request if client closes its output channel while waiting for the
  # request. HAProxy documentation has a long explanation for this option.
  option abortonclose

  # If sending a request to one worker fails, try to send it to another, 3 times
  # before aborting the request
  retries 3

  # Do not enforce session affinity (i.e., an HTTP session can be served by
  # any worker, not just the one that started the session
  option redispatch

  # Timeout a request if the client did not read any data for 120 seconds
  timeout client 120000

  # Timeout a request if Mongrel does not accept a connection for 120 seconds
  timeout connect 120000

  # Timeout a request if Mongrel does not accept the data on the connection,
  # or does not send a response back in 120 seconds
  timeout server 120000

  # Remove the server from the farm gracefully if the health check URI returns
  # a 404. This is useful for rolling restarts.
  http-check disable-on-404

  # Create a monitorable URI which returns a 200 if haproxy is up
  monitor-uri /haproxy/monitor

  # Amount of time after which a health check is considered to have timed out
  timeout check 2000

  # Errorfile
  # Return a file contents instead of errors generated by HAProxy
  errorfile 400 /etc/haproxy/errorfiles/400.http
  errorfile 403 /etc/haproxy/errorfiles/403.http
  errorfile 408 /dev/null # TODO: Why is this bitbucket instead of the normal haproxy file for a 408?
  errorfile 500 /etc/haproxy/errorfiles/500.http
  errorfile 502 /etc/haproxy/errorfiles/502.http
  errorfile 503 /etc/haproxy/errorfiles/503.http
  errorfile 504 /etc/haproxy/errorfiles/504.http

# Enable the statistics page
  stats enable
  stats hide-version
  stats uri     /haproxy?stats
  stats realm   Haproxy\ Statistics
  stats auth    <%= @haproxy_user %>:<%= @haproxy_pass %>

# Inbound to HAproxy traffic on port 80
frontend ingress_80
  bind *:80 mss 1422
  mode tcp
  default_backend egress_80

# Inbound to HAproxy traffic on port 443
frontend ingress_443
  bind *:443 mss 1422
  mode tcp
  default_backend egress_443

backend egress_80
<% if @httpchk_path -%>
  option httpchk HEAD <%= @httpchk_path %><% if @httpchk_host %> HTTP/1.1\r\nHost:\ <%= @httpchk_host %><% end %>
<% else -%>
  option httpchk HEAD / HTTP/1.1\r\nHost:\ _
<% end -%>
  http-check expect rstatus ((2|3)[0-9][0-9]|503|401)

<% if @backends.any? %>
  <% @backends.each_with_index do |instance, i| %>
  server app-<%= i %> <%= instance['private_hostname'] %>:8091 check inter 5000 fastinter 1000 fall 1 weight <%= (instance['role'] == 'app_master') ? @app_master_weight : 50 %> send-proxy-v2 # <%= instance['id'] %>
  <% end %>
<% else %>
  # It must be a solo.
  server solo 127.0.0.1:8091 check inter 5000 fastinter 1000 fall 1 weight 50 send-proxy-v2
<% end %>

backend egress_443
  mode tcp
<% if @httpchk_path -%>
  option httpchk HEAD <%= @httpchk_path %><% if @httpchk_host %> HTTP/1.1\r\nHost:\ <%= @httpchk_host %><% end %>
  http-check expect rstatus ((2|3)[0-9][0-9]|503|401)
<% else -%>
  option tcp-check
<% end -%>

<% if @backends.any? %>
  <% @backends.each_with_index do |instance, i| %>
  server app-<%= i %> <%= instance['private_hostname'] %>:8092 check check-ssl verify none inter 5000 fastinter 1000 fall 1 weight <%= (instance['role'] == 'app_master') ? @app_master_weight : 50 %> send-proxy-v2 # <%= instance['id'] %>
  <% end %>
<% else %>
  # It must be a solo.
  server solo 127.0.0.1:8092 check check-ssl verify none inter 5000 fastinter 1000 fall 1 weight 50 send-proxy-v2
<% end %>
